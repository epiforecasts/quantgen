% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/quantile_lasso.R
\name{quantile_lasso}
\alias{quantile_lasso}
\title{Quantile lasso}
\usage{
quantile_lasso(
  x,
  y,
  tau,
  lambda,
  weights = NULL,
  no_pen_vars = c(),
  intercept = TRUE,
  standardize = TRUE,
  lb = -Inf,
  ub = Inf,
  noncross = FALSE,
  x0 = NULL,
  lp_solver = c("glpk", "gurobi"),
  time_limit = NULL,
  warm_starts = TRUE,
  params = list(),
  transform = NULL,
  inv_trans = NULL,
  jitter = NULL,
  verbose = FALSE
)
}
\arguments{
\item{x}{Matrix of predictors. If sparse, then passing it an appropriate 
sparse \code{Matrix} class can greatly help optimization.}

\item{y}{Vector of responses.}

\item{tau, lambda}{Vectors of quantile levels and tuning parameter values. If
these are not of the same length, the shorter of the two is recycled so
that they become the same length. Then, for each \code{i}, we solve a
separate quantile lasso problem at quantile level \code{tau[i]} and tuning
parameter value \code{lambda[i]}. The most common use cases are: specifying
one tau value and a sequence of lambda values; or specifying a sequence of
tau values and one lambda value.}

\item{weights}{Vector of observation weights (to be used in the loss
function). Default is NULL, which is interpreted as a weight of 1 for each
observation.}

\item{no_pen_vars}{Indices of the variables that should be excluded from the
lasso penalty. Default is \code{c()}, which means that no variables are to
be excluded.}

\item{intercept}{Should an intercept be included in the regression model?
Default is TRUE.}

\item{standardize}{Should the predictors be standardized (to have unit
variance) before fitting? Default is TRUE.}

\item{lb, ub}{Lower and upper bounds, respectively, to place as constraints on
the coefficients in the optimization problem. These can be constants (to
place the same bound on each coefficient) or vectors of length equal to the
number of predictors (to place a potentially different bound on each
coefficient). Default is \code{-Inf} and \code{Inf} for \code{lb} and
\code{ub}, respectively, which effectively means no constraints are used.
Two important notes: when \code{intercept} is TRUE, the constraints are
*not* placed on the intercept; and when \code{standardize} is TRUE, the
constraints are placed on the *standardized scale* (they are used in the 
optimization problem whose predictors have been standardized).}

\item{noncross}{Should noncrossing constraints be applied? These force the
estimated quantiles to be properly ordered across all quantile levels being
considered. The default is FALSE. If TRUE, then noncrossing constraints are
applied to the estimated quantiles at all points specified by the next
argument \code{x0}. Note: this option only makes sense if the values in the
\code{tau} vector are distinct, and sorted in increasing order.}

\item{x0}{Matrix of points used to define the noncrossing
constraints. Default is NULL, which means that we consider noncrossing
constraints at the training points \code{x}.}

\item{lp_solver}{One of "glpk" or "gurobi", indicating which LP solver to
use. If possible, "gurobi" should be used because it is much faster and
more stable; default is "glpk"; however, because it is open-source.}

\item{time_limit}{This sets the maximum amount of time (in seconds) to allow
Gurobi or GLPK to solve any single quantile generalized lasso problem (for
a single tau and lambda value). Default is NULL, which means unlimited
time.}

\item{warm_starts}{Should warm starts be used in the LP solver (from one LP
solve to the next)? Only supported for Gurobi.}

\item{params}{List of control parameters to pass to Gurobi or GLPK. Default
is \code{list()} which means no additional parameters are passed. For
example: with Gurobi, we can use \code{list(Threads=4)} to specify that
Gurobi should use 4 threads when available. (Note that if a time limit is
specified through this \code{params} list, then its value will be overriden
by the last argument \code{time_limit}, assuming the latter is not NULL.)}

\item{transform, inv_trans}{The first is a function to transform y before
solving the quantile generalized lasso; the second is the corresponding
inverse transform. For example: for count data, we might want to model
log(1+y) (which would be the transform, and the inverse transform would be
exp(x)-1). Both \code{transform} and \code{inv_trans} should be
vectorized. Convenience functions \code{log_pad} and \code{exp_pad} are
provided (these are inverses), as well as \code{logit_pad} and
\code{sigmd_pad} (these are inverses).}

\item{jitter}{Function for applying random jitter to y, which might help
optimization. For example: for count data, there can be lots of ties (with
or without transformation of y), which can make optimization more
difficult. The function \code{jitter} should take an integer n and return n
random draws. A convenience function \code{unif_jitter} is provided.}

\item{verbose}{Should progress be printed out to the console? Default is
FALSE.}
}
\value{
A list with the following components:
  \item{beta}{Matrix of lasso coefficients, of dimension = (number of
  features + 1) x (number of quantile levels) assuming \code{intercept=TRUE},
  else (number of features) x (number of quantile levels). Note: these
  coefficients will always be on the appropriate scale; they are always on
  the scale of original features, even if \code{standardize=TRUE}}
  \item{status}{Vector of status flags returned by Gurobi's or GLPK's LP
  solver, of length = (number of quantile levels)}
  \item{tau,lambda}{Vectors of tau and lambda values used}
  \item{weights,no_pen_vars,...,jitter}{Values of these other arguments  
  used in the function call}
}
\description{
Compute quantile lasso solutions.
}
\details{
This function solves the quantile lasso problem, for each pair of
  quantile level \eqn{\tau} and tuning parameter \eqn{\lambda}:  
  \deqn{\mathop{\mathrm{minimize}}_{\beta_0,\beta} \;
  \sum_{i=1}^n w_i \psi_\tau(y_i-\beta_0-x_i^T\beta) + \lambda \|\beta\|_1}    
  for a response vector \eqn{y} with components \eqn{y_i}, and predictor
  matrix \eqn{X} with rows \eqn{x_i}. Here \eqn{\psi_\tau(v) = \max\{\tau v, 
  (\tau-1) v\}} is the "pinball" or "tilted \eqn{\ell_1}" loss. When
  noncrossing constraints are applied, we instead solve one big joint
  optimization, over all quantile levels and tuning parameter values: 
  \deqn{\mathop{\mathrm{minimize}}_{\beta_{0k}, \beta_k, k=1,\ldots,r} \; 
  \sum_{k=1}^r \bigg(\sum_{i=1}^n w_i \psi_{\tau_k}(y_i-\beta_{0k}-
  x_i^T\beta_k) + \lambda_k \|\beta_k\|_1\bigg)} 
  \deqn{\mathrm{subject \; to} \;\; \beta_{0k}+x^T\beta_k \leq
  \beta_{0,k+1}+x^T\beta_{k+1} \;\; k=1,\ldots,r-1, \; x \in \mathcal{X}}
  where the quantile levels \eqn{\tau_j, j=1,\ldots,k} are assumed to be in
  increasing order, and \eqn{\mathcal{X}} is a collection of points over
  which to enforce the noncrossing constraints.

  Either problem is readily converted into a linear program (LP), and solved
  using either Gurobi (which is free for academic use, and generally fast) or
  GLPK (which free for everyone, but slower).

  All arguments not described above are as in the \code{quantile_genlasso}
  function. The associated \code{coef} and \code{predict} functions are just
  those for the \code{quantile_genlasso} class.
}
\author{
Ryan Tibshirani
}
