% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/quantile_lasso.R
\name{cv_quantile_lasso}
\alias{cv_quantile_lasso}
\title{Cross-validation for quantile lasso}
\usage{
cv_quantile_lasso(
  x,
  y,
  tau,
  lambda = NULL,
  nlambda = 30,
  lambda_min_ratio = 0.001,
  weights = NULL,
  no_pen_vars = c(),
  nfolds = 5,
  train_test_inds = NULL,
  intercept = TRUE,
  standardize = TRUE,
  lb = -Inf,
  ub = Inf,
  noncross = FALSE,
  x0 = NULL,
  lp_solver = c("glpk", "gurobi"),
  time_limit = NULL,
  warm_starts = TRUE,
  params = list(),
  transform = NULL,
  inv_trans = NULL,
  jitter = NULL,
  verbose = FALSE,
  sort = FALSE,
  iso = FALSE,
  nonneg = FALSE,
  round = FALSE
)
}
\arguments{
\item{x}{Matrix of predictors. If sparse, then passing it an appropriate 
sparse \code{Matrix} class can greatly help optimization.}

\item{y}{Vector of responses.}

\item{tau, lambda}{Vectors of quantile levels and tuning parameter values. If
these are not of the same length, the shorter of the two is recycled so
that they become the same length. Then, for each \code{i}, we solve a
separate quantile lasso problem at quantile level \code{tau[i]} and tuning
parameter value \code{lambda[i]}. The most common use cases are: specifying
one tau value and a sequence of lambda values; or specifying a sequence of
tau values and one lambda value.}

\item{nlambda}{Number of lambda values to consider, for each quantile
level. Default is 30.}

\item{lambda_min_ratio}{Ratio of the minimum to maximum lambda value, for
each quantile levels. Default is 1e-3.}

\item{weights}{Vector of observation weights (to be used in the loss
function). Default is NULL, which is interpreted as a weight of 1 for each
observation.}

\item{no_pen_vars}{Indices of the variables that should be excluded from the
lasso penalty. Default is \code{c()}, which means that no variables are to
be excluded.}

\item{nfolds}{Number of cross-validation folds. Default is 5.}

\item{train_test_inds}{List of length two, with components named \code{train}
and \code{test}. Each of \code{train} and \code{test} are themselves lists,
of the same length; for each \code{i}, we will consider \code{train[[i]]}
the indices (which index the rows of \code{x} and elements of \code{y}) to
use for training, and \code{test[[i]]} as the indices to use for testing
(validation). The validation error will then be summed up over all
\code{i}. This allows for fine control of the "cross-validation" process
(in quotes, because there need not be any crossing going on here). Default
is NULL; if specified, takes priority over \code{nfolds}.}

\item{intercept}{Should an intercept be included in the regression model?
Default is TRUE.}

\item{standardize}{Should the predictors be standardized (to have unit
variance) before fitting? Default is TRUE.}

\item{lb, ub}{Lower and upper bounds, respectively, to place as constraints on
the coefficients in the optimization problem. These can be constants (to
place the same bound on each coefficient) or vectors of length equal to the
number of predictors (to place a potentially different bound on each
coefficient). Default is \code{-Inf} and \code{Inf} for \code{lb} and
\code{ub}, respectively, which effectively means no constraints are used.
Two important notes: when \code{intercept} is TRUE, the constraints are
*not* placed on the intercept; and when \code{standardize} is TRUE, the
constraints are placed on the *standardized scale* (they are used in the 
optimization problem whose predictors have been standardized).}

\item{noncross}{Should noncrossing constraints be applied? These force the
estimated quantiles to be properly ordered across all quantile levels being
considered. The default is FALSE. If TRUE, then noncrossing constraints are
applied to the estimated quantiles at all points specified by the next
argument \code{x0}. Note: this option only makes sense if the values in the
\code{tau} vector are distinct, and sorted in increasing order.}

\item{x0}{Matrix of points used to define the noncrossing
constraints. Default is NULL, which means that we consider noncrossing
constraints at the training points \code{x}.}

\item{lp_solver}{One of "glpk" or "gurobi", indicating which LP solver to
use. If possible, "gurobi" should be used because it is much faster and
more stable; default is "glpk"; however, because it is open-source.}

\item{time_limit}{This sets the maximum amount of time (in seconds) to allow
Gurobi or GLPK to solve any single quantile generalized lasso problem (for
a single tau and lambda value). Default is NULL, which means unlimited
time.}

\item{warm_starts}{Should warm starts be used in the LP solver (from one LP
solve to the next)? Only supported for Gurobi.}

\item{params}{List of control parameters to pass to Gurobi or GLPK. Default
is \code{list()} which means no additional parameters are passed. For
example: with Gurobi, we can use \code{list(Threads=4)} to specify that
Gurobi should use 4 threads when available. (Note that if a time limit is
specified through this \code{params} list, then its value will be overriden
by the last argument \code{time_limit}, assuming the latter is not NULL.)}

\item{transform, inv_trans}{The first is a function to transform y before
solving the quantile generalized lasso; the second is the corresponding
inverse transform. For example: for count data, we might want to model
log(1+y) (which would be the transform, and the inverse transform would be
exp(x)-1). Both \code{transform} and \code{inv_trans} should be
vectorized. Convenience functions \code{log_pad} and \code{exp_pad} are
provided (these are inverses), as well as \code{logit_pad} and
\code{sigmd_pad} (these are inverses).}

\item{jitter}{Function for applying random jitter to y, which might help
optimization. For example: for count data, there can be lots of ties (with
or without transformation of y), which can make optimization more
difficult. The function \code{jitter} should take an integer n and return n
random draws. A convenience function \code{unif_jitter} is provided.}

\item{verbose}{Should progress be printed out to the console? Default is
FALSE.}

\item{sort}{Should the returned quantile estimates be sorted? Default is
FALSE. Note: this option only makes sense if the values in the stored
\code{tau} vector are distinct, and sorted in increasing order.}

\item{iso}{Should the returned quantile estimates be passed through isotonic
regression? Default is FALSE; if TRUE, takes priority over \code{sort}.
Note: this option only makes sense if the values in the stored \code{tau}
vector are distinct, and sorted in increasing order.}

\item{nonneg}{Should the returned quantile estimates be truncated at 0?
Natural for count data. Default is FALSE.}

\item{round}{Should the returned quantile estimates be rounded? Natural for
count data. Default is FALSE.}
}
\value{
A list with the following components:
  \item{qgl_obj}{A \code{quantile_lasso} object obtained by fitting on the
  full training set, at all quantile levels and their corresponding optimal
  lambda values}
  \item{cv_mat}{Matrix of cross-validation errors (as measured by quantile
  loss), of dimension (number of tuning parameter values) x (number of
  quantile levels)}
  \item{lambda_min}{Vector of optimum lambda values, one per quantile level}
}
\description{
Run cross-validation for the quantile lasso on a tau by lambda grid. For each
tau, the lambda value minimizing the cross-validation error is reported.
}
\details{
All arguments through \code{verbose} (except for \code{nfolds} and
  \code{train_test_inds}) are as in \code{quantile_lasso_grid} and
  \code{quantile_lasso}. Note that the \code{noncross} and \code{x0}
  arguments are not passed to \code{quantile_lasso_grid} for the calculation
  of cross-validation errors and optimal lambda values; they are only passed
  to \code{quantile_lasso} for the final object that is fit to the full
  training set. Past \code{verbose}, the arguments are as in
  \code{predict.quantile_lasso}, and control what happens with the
  predictions made on the validation sets. The associated \code{predict}
  function is just that for the \code{cv_quantile_genlasso} class.
}
